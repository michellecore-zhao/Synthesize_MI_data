# Synthesize_MI_data
Comparision between measurements and synthetic data
Generate synthetic MI motion data using MoCap data

### INPUTS: 

* Videos: golestani, negar (2020): INPUT: video. figshare. Media. https://doi.org/10.6084/m9.figshare.11803653

* VNA Measurements: golestani, negar (2020): INPUT: VNA measurement. figshare. Dataset. https://doi.org/10.6084/m9.figshare.11803659

* BML MoCap (Public Dataset): 
Ma, Y., Paterson, H. M. & Pollick, F. E. A motion capture library for the study of identity, gender, and emotion perception from biological motion. Behav. Res. Methods 38, 134â€“141 (2006). 
URL: http://paco.psy.gla.ac.uk/?portfolio_page=body-movement-library 

* MHAD MoCap (Public Dataset): F. Ofli, R. Chaudhry, G. Kurillo, R. Vidal and R. Bajcsy. Berkeley MHAD: A Comprehensive Multimodal Human Action Database. In Proceedings of the IEEE Workshop on Applications on Computer Vision (WACV), 2013. 
URL: https://tele-immersion.citris-uc.org/berkeley_mhad 
 
 
 ### OUTPUTS:

* Synthetic MI Motion (BML): golestani, negar (2020): Biological Motion Library (BML). figshare. Dataset. https://doi.org/10.6084/m9.figshare.11809326

* Synthetic MI Motion (MHAD): golestani, negar (2020): Berkeley Multimodal Human Action Database (MHAD). figshare. Dataset. https://doi.org/10.6084/m9.figshare.11809470
